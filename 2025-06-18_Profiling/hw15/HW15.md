# [15] Профилирование запросов

```sql
SELECT
    version(),
    toDate(now('Europe/Moscow'))
FORMAT Raw

25.4.2.31       2025-06-22
```

## Демонстрационный датасет

Будем использовать наш традиционный датасет [New York Taxi Data](https://clickhouse.com/docs/getting-started/example-datasets/nyc-taxi). Не буду здесь приводить текст SQL запросов на создание таблицы *nyc_taxi.trips_small* и заполнение её данными, потому что они просто скопированы со страницы с описанием датасета.

Посмотрим на параметры таблицы:

```sql
SELECT
    database,
    name,
    engine,
    primary_key,
    total_rows,
    active_parts,
    total_marks
FROM system.tables
WHERE database IN ('nyc_taxi')

   ┌─database─┬─name────────┬─engine────┬─primary_key───────────────────────┬─total_rows─┬─active_parts─┬─total_marks─┐
1. │ nyc_taxi │ trips_small │ MergeTree │ pickup_datetime, dropoff_datetime │    3000317 │            3 │         371 │
   └──────────┴─────────────┴───────────┴───────────────────────────────────┴────────────┴──────────────┴─────────────┘

1 row in set. Elapsed: 0.003 sec.
```

Проверим состояние партов таблицы:

```sql
SELECT
    database,
    `table`,
    name,
    rows,
    marks,
    primary_key_size
FROM system.parts
WHERE database IN ('nyc_taxi')

   ┌─database─┬─table───────┬─name──────┬────rows─┬─marks─┬─primary_key_size─┐
1. │ nyc_taxi │ trips_small │ all_1_1_0 │ 1111953 │   137 │             1008 │
2. │ nyc_taxi │ trips_small │ all_2_2_0 │ 1084766 │   134 │             1014 │
3. │ nyc_taxi │ trips_small │ all_3_3_0 │  803598 │   100 │              774 │
   └──────────┴─────────────┴───────────┴─────────┴───────┴──────────────────┘

3 rows in set. Elapsed: 0.006 sec.
```

## Запросы

Будем запрашивать статистку поездок с группировкой по способу оплаты. Но при этом рассмотрим следующие варианты выбора подмножества записей для агрегации (условие [`WHERE`](https://clickhouse.com/docs/sql-reference/statements/select/where) запроса):

1. Фильтр по полю **pickup_datetime**, которое находится на *первой* позиции в составном первичном ключе.
2. Фильтр по полю **dropoff_datetime**, которое находится на *второй* позиции в составном первичном ключе.
3. Фильтр по полю **total_amount**, которое вообще не входит в первичный ключ.

Для каждого запроса будем включать опцию [`send_logs_level`](https://clickhouse.com/docs/knowledgebase/send_logs_level), чтобы также получить от сервера текстовые логи исполнения запроса.

### Фильтр по *первому* полю первичного ключа

Здесь будем использовать условие по полю **pickup_datetime**, которое входит в составной [первичный ключ](https://clickhouse.com/docs/guides/best-practices/sparse-primary-indexes) таблицы на [*первой*](https://clickhouse.com/docs/guides/best-practices/sparse-primary-indexes#the-primary-index-is-used-for-selecting-granules) позиции. Другими словами, данные в таблице глобально отсортированы по значению этого поля. Таким образом, в этом случае может быть использован двоичный поиск.

```sql
SELECT
    payment_type,
    count(*) AS total_trips,
    sum(passenger_count) AS total_passengers,
    round(avg(total_amount), 2) AS avg_price,
    round(avg(trip_distance), 2) AS avg_distance
FROM nyc_taxi.trips_small
WHERE (pickup_datetime >= toDateTime('2015-07-01')) AND (pickup_datetime <= toDateTime('2015-08-01'))
GROUP BY payment_type
ORDER BY payment_type ASC
SETTINGS send_logs_level = 'trace'

Query id: e49cc4c8-bafb-402d-8100-458b405ca71e

. . . . .
< log lines omitted here, see an excerpt below >
. . . . .

   ┌─payment_type─┬─total_trips─┬─total_passengers─┬─avg_price─┬─avg_distance─┐
1. │ CSH          │      357145 │           596623 │     17.69 │         3.74 │
2. │ CRE          │      218651 │           382297 │     13.54 │         2.78 │
3. │ NOC          │        1979 │             2519 │     13.61 │         3.18 │
4. │ DIS          │         669 │              875 │     12.69 │         2.78 │
   └──────────────┴─────────────┴──────────────────┴───────────┴──────────────┘

4 rows in set. Elapsed: 0.028 sec. Processed 589.82 thousand rows, 8.26 MB (20.94 million rows/s., 293.19 MB/s.)
Peak memory usage: 1.08 MiB.
```

Фрагмент лога, который позволяет подтвердить использование основного индекса представлен ниже. [Полный лог](https://github.com/rklepov/OTUS-ClickHouse-2025-03/blob/main/2025-06-18_Profiling/hw15/pickup_datetime.txt "pickup_datetime.txt") запроса доступен в текущем репозитории.

<details>

<summary>pickup_datetime.txt</summary>

```text
[3e16fa9ca9d8] 2025.06.23 07:30:45.934472 [ 79 ] {e49cc4c8-bafb-402d-8100-458b405ca71e} <Trace> QueryPlanOptimizePrewhere: Moved 2 conditions to PREWHERE
[3e16fa9ca9d8] 2025.06.23 07:30:45.935784 [ 79 ] {e49cc4c8-bafb-402d-8100-458b405ca71e} <Debug> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Key condition: (column 0 in [1435708800, +Inf)), (column 0 in (-Inf, 1438387200]), and
[3e16fa9ca9d8] 2025.06.23 07:30:45.935923 [ 79 ] {e49cc4c8-bafb-402d-8100-458b405ca71e} <Trace> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Filtering marks by primary and secondary keys
. . . . .
[3e16fa9ca9d8] 2025.06.23 07:30:45.936478 [ 732 ] {e49cc4c8-bafb-402d-8100-458b405ca71e} <Trace> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Running binary search on index range for part all_1_1_0 (137 marks)
[3e16fa9ca9d8] 2025.06.23 07:30:45.936568 [ 732 ] {e49cc4c8-bafb-402d-8100-458b405ca71e} <Trace> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Found (LEFT) boundary mark: 0
[3e16fa9ca9d8] 2025.06.23 07:30:45.936625 [ 732 ] {e49cc4c8-bafb-402d-8100-458b405ca71e} <Trace> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Found (RIGHT) boundary mark: 48
[3e16fa9ca9d8] 2025.06.23 07:30:45.937162 [ 732 ] {e49cc4c8-bafb-402d-8100-458b405ca71e} <Trace> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Found continuous range in 14 steps
. . . . .
[3e16fa9ca9d8] 2025.06.23 07:30:45.937637 [ 79 ] {e49cc4c8-bafb-402d-8100-458b405ca71e} <Debug> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Query condition cache has dropped 0/72 granules for PREWHERE condition and(greaterOrEquals(__table1.pickup_datetime, _CAST(1435708800_DateTime, 'DateTime'_String)), lessOrEquals(__table1.pickup_datetime, _CAST(1438387200_DateTime, 'DateTime'_String))).
[3e16fa9ca9d8] 2025.06.23 07:30:45.937762 [ 79 ] {e49cc4c8-bafb-402d-8100-458b405ca71e} <Debug> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Query condition cache has dropped 0/72 granules for WHERE condition and(greaterOrEquals(pickup_datetime, _CAST(1435708800_DateTime, 'DateTime'_String)), lessOrEquals(pickup_datetime, _CAST(1438387200_DateTime, 'DateTime'_String))).
[3e16fa9ca9d8] 2025.06.23 07:30:45.937808 [ 79 ] {e49cc4c8-bafb-402d-8100-458b405ca71e} <Debug> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Selected 3/3 parts by partition key, 2 parts by primary key, 72/368 marks by primary key, 72 marks to read from 2 ranges
[3e16fa9ca9d8] 2025.06.23 07:30:45.938456 [ 79 ] {e49cc4c8-bafb-402d-8100-458b405ca71e} <Debug> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Reading approx. 589824 rows with 3 streams
```

</details>

Как можно видеть по логу запроса, для фильтрации записей действительно был использован двоичный поиск: *Running binary search on index range for part all_1_1_0 (137 marks)*.

[Анализатор](https://clickhouse.com/docs/guides/developer/understanding-query-execution-with-the-analyzer#planner) запроса также подтверждает использование основного индекса:

```sql
EXPLAIN indexes = 1
SELECT
    payment_type,
    count(*) AS total_trips,
    sum(passenger_count) AS total_passengers,
    round(avg(total_amount), 2) AS avg_price,
    round(avg(trip_distance), 2) AS avg_distance
FROM nyc_taxi.trips_small
WHERE (pickup_datetime >= toDateTime('2015-07-01')) AND (pickup_datetime <= toDateTime('2015-08-01'))
GROUP BY payment_type
ORDER BY payment_type ASC
FORMAT Raw

Expression ((Project names + (Before ORDER BY + Projection) [lifted up part]))
  Sorting (Sorting for ORDER BY)
    Expression ((Before ORDER BY + Projection))
      Aggregating
        Expression (Before GROUP BY)
          Expression
            ReadFromMergeTree (nyc_taxi.trips_small)
            Indexes:
              PrimaryKey
                Keys:
                  pickup_datetime
                Condition: and((pickup_datetime in (-Inf, 1438387200]), (pickup_datetime in [1435708800, +Inf)))
                Parts: 2/3
                Granules: 72/368

14 rows in set. Elapsed: 0.005 sec.
```

Можно обратить внимание, что использование индекса позволило существенно сократить количество отобранных гранул (72/368).

### Фильтр по *второму* полю первичного ключа

Здесь будем использовать условие по полю **dropoff_datetime**, которое входит в первичный ключ на *второй* позиции. В этом случае двоичный поиск невозможен, однако *ClickHouse* использует алгоритм [*Generic exclusion search*](https://clickhouse.com/docs/guides/best-practices/sparse-primary-indexes#generic-exclusion-search-algorithm), описанный в документации.

```sql
SELECT
    payment_type,
    count(*) AS total_trips,
    sum(passenger_count) AS total_passengers,
    round(avg(total_amount), 2) AS avg_price,
    round(avg(trip_distance), 2) AS avg_distance
FROM nyc_taxi.trips_small
WHERE (dropoff_datetime >= toDateTime('2015-07-01')) AND (dropoff_datetime <= toDateTime('2015-08-01'))
GROUP BY payment_type
ORDER BY payment_type ASC
SETTINGS send_logs_level = 'trace'

Query id: 2c5706fe-601b-48f2-b29e-88df9959d6c4

. . . . .
< log lines omitted here, see an excerpt below >
. . . . .

   ┌─payment_type─┬─total_trips─┬─total_passengers─┬─avg_price─┬─avg_distance─┐
1. │ CSH          │      356924 │           596222 │     17.69 │         3.74 │
2. │ CRE          │      218553 │           382107 │     13.53 │         2.78 │
3. │ NOC          │        1978 │             2518 │      13.6 │         3.18 │
4. │ DIS          │         669 │              875 │     12.69 │         2.78 │
   └──────────────┴─────────────┴──────────────────┴───────────┴──────────────┘

4 rows in set. Elapsed: 0.046 sec. Processed 589.82 thousand rows, 8.26 MB (12.79 million rows/s., 179.13 MB/s.)
Peak memory usage: 803.23 KiB.
```

По фрагменту лога ниже видно, что действительно был использован алгоритм &laquo;поиска исключений&raquo;: *Used generic exclusion search over index for part all_1_1_0 with 193 steps*. [Полный лог](https://github.com/rklepov/OTUS-ClickHouse-2025-03/blob/main/2025-06-18_Profiling/hw15/dropoff_datetime.txt "dropoff_datetime.txt") запроса доступен в текущем репозитории.

<details>

<summary>dropoff_datetime.txt</summary>

```text
[3e16fa9ca9d8] 2025.06.23 08:10:59.179349 [ 79 ] {2c5706fe-601b-48f2-b29e-88df9959d6c4} <Trace> QueryPlanOptimizePrewhere: Moved 2 conditions to PREWHERE
[3e16fa9ca9d8] 2025.06.23 08:10:59.180887 [ 79 ] {2c5706fe-601b-48f2-b29e-88df9959d6c4} <Debug> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Key condition: (column 1 in [1435708800, +Inf)), (column 1 in (-Inf, 1438387200]), and
[3e16fa9ca9d8] 2025.06.23 08:10:59.181073 [ 79 ] {2c5706fe-601b-48f2-b29e-88df9959d6c4} <Trace> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Filtering marks by primary and secondary keys
. . . . .
[3e16fa9ca9d8] 2025.06.23 08:10:59.181851 [ 914 ] {2c5706fe-601b-48f2-b29e-88df9959d6c4} <Trace> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Used generic exclusion search over index for part all_1_1_0 with 193 steps
[3e16fa9ca9d8] 2025.06.23 08:10:59.182918 [ 919 ] {2c5706fe-601b-48f2-b29e-88df9959d6c4} <Trace> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Used generic exclusion search over index for part all_2_2_0 with 191 steps
[3e16fa9ca9d8] 2025.06.23 08:10:59.189162 [ 914 ] {2c5706fe-601b-48f2-b29e-88df9959d6c4} <Trace> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Used generic exclusion search over index for part all_3_3_0 with 150 steps
. . . . .
[3e16fa9ca9d8] 2025.06.23 08:10:59.190467 [ 79 ] {2c5706fe-601b-48f2-b29e-88df9959d6c4} <Debug> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Query condition cache has dropped 296/368 granules for PREWHERE condition and(greaterOrEquals(__table1.dropoff_datetime, _CAST(1435708800_DateTime, 'DateTime'_String)), lessOrEquals(__table1.dropoff_datetime, _CAST(1438387200_DateTime, 'DateTime'_String))).
[3e16fa9ca9d8] 2025.06.23 08:10:59.190792 [ 79 ] {2c5706fe-601b-48f2-b29e-88df9959d6c4} <Debug> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Query condition cache has dropped 0/72 granules for WHERE condition and(greaterOrEquals(dropoff_datetime, _CAST(1435708800_DateTime, 'DateTime'_String)), lessOrEquals(dropoff_datetime, _CAST(1438387200_DateTime, 'DateTime'_String))).
[3e16fa9ca9d8] 2025.06.23 08:10:59.191245 [ 79 ] {2c5706fe-601b-48f2-b29e-88df9959d6c4} <Debug> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Selected 3/3 parts by partition key, 2 parts by primary key, 368/368 marks by primary key, 72 marks to read from 2 ranges
[3e16fa9ca9d8] 2025.06.23 08:10:59.192318 [ 79 ] {2c5706fe-601b-48f2-b29e-88df9959d6c4} <Debug> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Reading approx. 589824 rows with 3 streams
```

</details>

Посмотрим на результат анализатора запросов:

```sql
EXPLAIN indexes = 1
SELECT
    payment_type,
    count(*) AS total_trips,
    sum(passenger_count) AS total_passengers,
    round(avg(total_amount), 2) AS avg_price,
    round(avg(trip_distance), 2) AS avg_distance
FROM nyc_taxi.trips_small
WHERE (dropoff_datetime >= toDateTime('2015-07-01')) AND (dropoff_datetime <= toDateTime('2015-08-01'))
GROUP BY payment_type
ORDER BY payment_type ASC
FORMAT raw

Expression ((Project names + (Before ORDER BY + Projection) [lifted up part]))
  Sorting (Sorting for ORDER BY)
    Expression ((Before ORDER BY + Projection))
      Aggregating
        Expression (Before GROUP BY)
          Expression
            ReadFromMergeTree (nyc_taxi.trips_small)
            Indexes:
              PrimaryKey
                Keys:
                  dropoff_datetime
                Condition: and((dropoff_datetime in (-Inf, 1438387200]), (dropoff_datetime in [1435708800, +Inf)))
                Parts: 3/3
                Granules: 368/368

14 rows in set. Elapsed: 0.007 sec.
```

Можно обратить внимание, что, хотя анализатор и указывает на использование первичного индекса (очевидно, в варианте &laquo;поиска исключений&raquo;), тем не менее поиск затрагивает все гранулы (368/368).

Как отмечено в [документации](https://clickhouse.com/docs/guides/best-practices/sparse-primary-indexes#generic-exclusion-search-algorithm), эффективность алгоритма *generic exclusion search* зависит от кардинальности предшествующего поля в составном ключе:

> The [generic exclusion search algorithm](https://github.com/ClickHouse/ClickHouse/blob/22.3/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp#L1444) that ClickHouse is using instead of the [binary search algorithm](https://github.com/ClickHouse/ClickHouse/blob/22.3/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp#L1452) when a query is filtering on a column that is part of a compound key, but is not the first key column is most effective when the predecessor key column has low(er) cardinality.

В нашем случае предшествующим полем является **pickup_datetime**. Очевидно, что у этого поля высокая кардинальность (это метка времени). Тем не менее специфика данных состоит в том, что значения **dropoff_datetime** распределены не произвольно, а очевидным образом зависят от соответствующих значений **pickup_datetime**.

Таким образом, в данном случае алгоритм &laquo;поиска исключений&raquo; работает относительно эффективно и много лишних гранул отбрасывается уже на уровне индекса, что можно видеть по логу: *Query condition cache has dropped 296/368 granules for PREWHERE condition*.

Как итог, общее число обрабатываемых записей получается такое же, как и в случае двоичного поиска по основному индексу: *Reading approx. 589824 rows with 3 streams*. При этом, естественно, сам поиск по индексу работает менее эффективно.

### Запрос без использования первичного ключа

Наконец, попробуем фильтрацию по значению поля **total_amount**, которое вообще не входит в первичный ключ. Очевидно, что в этом случае будет использоваться линейный поиск, то есть полный перебор записей таблицы (*full scan*).

```sql
SELECT
    payment_type,
    count(*) AS total_trips,
    sum(passenger_count) AS total_passengers,
    round(avg(total_amount), 2) AS avg_price,
    round(avg(trip_distance), 2) AS avg_distance
FROM nyc_taxi.trips_small
WHERE total_amount > 50
GROUP BY payment_type
ORDER BY payment_type ASC
SETTINGS send_logs_level = 'trace'

Query id: 1743ccf1-12bc-42c2-914a-9794f7b42e41

. . . . .
< log lines omitted here, see an excerpt below >
. . . . .

   ┌─payment_type─┬─total_trips─┬─total_passengers─┬─avg_price─┬─avg_distance─┐
1. │ CSH          │       87276 │           149293 │     67.47 │        16.15 │
2. │ CRE          │       34259 │            65314 │     63.85 │        17.54 │
3. │ NOC          │         744 │             1051 │     69.17 │        10.48 │
4. │ DIS          │         200 │              275 │     62.52 │        11.41 │
   └──────────────┴─────────────┴──────────────────┴───────────┴──────────────┘

4 rows in set. Elapsed: 0.073 sec. Processed 3.00 million rows, 30.00 MB (40.94 million rows/s., 409.37 MB/s.)
Peak memory usage: 1.31 MiB.
```

По логу запроса видно, что в данном случае никакие индексы не использовались. Фрагмент лога представлен ниже. [Полный лог](https://github.com/rklepov/OTUS-ClickHouse-2025-03/blob/main/2025-06-18_Profiling/hw15/total_amount.txt "total_amount.txt") запроса доступен в текущем репозитории.

<details>

<summary>total_amount.txt</summary>

```text
[3e16fa9ca9d8] 2025.06.23 08:40:40.764198 [ 79 ] {1743ccf1-12bc-42c2-914a-9794f7b42e41} <Trace> QueryPlanOptimizePrewhere: Moved 1 conditions to PREWHERE
[3e16fa9ca9d8] 2025.06.23 08:40:40.764815 [ 79 ] {1743ccf1-12bc-42c2-914a-9794f7b42e41} <Debug> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Key condition: unknown
[3e16fa9ca9d8] 2025.06.23 08:40:40.764893 [ 79 ] {1743ccf1-12bc-42c2-914a-9794f7b42e41} <Trace> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Filtering marks by primary and secondary keys
. . . . .
[3e16fa9ca9d8] 2025.06.23 08:40:40.769506 [ 79 ] {1743ccf1-12bc-42c2-914a-9794f7b42e41} <Debug> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Query condition cache has dropped 0/368 granules for PREWHERE condition greater(__table1.total_amount, 50_UInt8).
[3e16fa9ca9d8] 2025.06.23 08:40:40.769651 [ 79 ] {1743ccf1-12bc-42c2-914a-9794f7b42e41} <Debug> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Query condition cache has dropped 0/368 granules for WHERE condition greater(total_amount, 50_UInt8).
[3e16fa9ca9d8] 2025.06.23 08:40:40.769690 [ 79 ] {1743ccf1-12bc-42c2-914a-9794f7b42e41} <Debug> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Selected 3/3 parts by partition key, 3 parts by primary key, 368/368 marks by primary key, 368 marks to read from 3 ranges
[3e16fa9ca9d8] 2025.06.23 08:40:40.769904 [ 79 ] {1743ccf1-12bc-42c2-914a-9794f7b42e41} <Debug> nyc_taxi.trips_small (d54e7c83-f651-4bef-b9ac-2b4dc1911881) (SelectExecutor): Reading approx. 3000317 rows with 4 streams
```

</details>

Также посмотрим на результат команды [`EXPLAIN`](https://clickhouse.com/docs/sql-reference/statements/explain#explain-plan):

```sql
EXPLAIN indexes = 1
SELECT
    payment_type,
    count(*) AS total_trips,
    sum(passenger_count) AS total_passengers,
    round(avg(total_amount), 2) AS avg_price,
    round(avg(trip_distance), 2) AS avg_distance
FROM nyc_taxi.trips_small
WHERE total_amount > 50
GROUP BY payment_type
ORDER BY payment_type ASC
FORMAT Raw

Expression ((Project names + (Before ORDER BY + Projection) [lifted up part]))
  Sorting (Sorting for ORDER BY)
    Expression ((Before ORDER BY + Projection))
      Aggregating
        Expression (Before GROUP BY)
          Expression
            ReadFromMergeTree (nyc_taxi.trips_small)
            Indexes:
              PrimaryKey
                Condition: true
                Parts: 3/3
                Granules: 368/368

12 rows in set. Elapsed: 0.059 sec.
```

Здесь также видно, что индекс не использовался: *Condition: true*, очевидно, означает, что надо проверять каждую запись. Последнее подтверждается и логом запроса: *Reading approx. 3000317 rows with 4 streams*.
