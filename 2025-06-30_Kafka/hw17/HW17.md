# [17] Интеграция с Apache Kafka

> Я работаю локально через [VirtualBox](https://www.virtualbox.org/) на Linux [CentOS 9](https://www.centos.org/stream9/).

## Архитектура решения

В данном задании я буду в целом повторять схему, описанную в статье [*Using the Kafka table engine*](https://clickhouse.com/docs/integrations/kafka/kafka-table-engine). Используемый датасет также из этой статьи: информация о событиях в репозитории *ClickHouse* на *Github*.

Все файлы конфигурации можно найти в текущем [репозитории](https://github.com/rklepov/OTUS-ClickHouse-2025-03/tree/main/2025-06-30_Kafka/hw17).

### Apache Kafka

```shell
[appuser@kafka1 ~]$ kafka-topics --version
7.8.0-ccs
```

*Kafka* будет запускаться в контейнере *Docker*. Файл конфигурации для *docker compose* скопирован из *Github* репозитория [*kafka-stack-docker-compose*](https://github.com/conduktor/kafka-stack-docker-compose.git). Будем использовать самый простой вариант конфигурации: *Single Zookeeper / Single Kafka*.

<details>

<summary>zk-single-kafka-single.yml</summary>

```yaml
services:
  zoo1:
    image: confluentinc/cp-zookeeper:7.8.0
    hostname: zoo1
    container_name: zoo1
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zoo1:2888:3888

  kafka1:
    image: confluentinc/cp-kafka:7.8.0
    hostname: kafka1
    container_name: kafka1
    ports:
      - "9092:9092"
      - "29092:29092"
      - "9999:9999"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_JMX_PORT: 9999
      KAFKA_JMX_HOSTNAME: ${DOCKER_HOST_IP:-127.0.0.1}
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    depends_on:
      - zoo1
```

</details>

### ClickHouse

```sql
SELECT version()
FORMAT Raw

25.6.4.12
```

 *ClickHouse* также работает в контейнере *Docker*. Поскольку у меня локальная установка *Kafka*, то дополнительной настройки *ClickHouse* (пароли, сертификаты и т.п.) не требуется.

<details>

<summary>clickhouse.yml</summary>

```yaml
version: "3.8"

services:
  clickhouse:
    image: "clickhouse/clickhouse-server:latest"
    user: "0:0"
    hostname: clickhouse
    volumes:
      - clickhouse_vol:/var/lib/clickhouse
      - ${PWD}/fs/volumes/clickhouse/etc/clickhouse-server/config.d/config.xml:/etc/clickhouse-server/config.d/config.xml:Z
      - ${PWD}/fs/volumes/clickhouse/etc/clickhouse-server/users.d/users.xml:/etc/clickhouse-server/users.d/users.xml:Z
    ports:
      - "0.0.0.0:18123:8123"
      - "0.0.0.0:19000:9000"

volumes:
  clickhouse_vol:
    driver: local
```

</details>

Запустим контейнеры с *Kafka* и *ClickHouse*:

```shell
$ docker compose -f zk-single-kafka-single.yml -f clickhouse.yml up -d
. . . . .

$ docker ps
CONTAINER ID  IMAGE                                          COMMAND               CREATED         STATUS         PORTS                                                                     NAMES
98e43969bcce  docker.io/confluentinc/cp-zookeeper:7.8.0      /etc/confluent/do...  19 minutes ago  Up 19 minutes  0.0.0.0:2181->2181/tcp, 2888/tcp, 3888/tcp                                zoo1
b893e6cc8d17  docker.io/clickhouse/clickhouse-server:latest                        19 minutes ago  Up 19 minutes  0.0.0.0:18123->8123/tcp, 0.0.0.0:19000->9000/tcp, 9009/tcp                hw17_clickhouse_1
f9e44e74b2e7  docker.io/confluentinc/cp-kafka:7.8.0          /etc/confluent/do...  19 minutes ago  Up 19 minutes  0.0.0.0:9092->9092/tcp, 0.0.0.0:9999->9999/tcp, 0.0.0.0:29092->29092/tcp  kafka1
```

## Топики *Kafka*

Зайдём в контейнер *Kafka* и с помощью команды [`kafka-topics`](https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-topics-sh) сразу создадим два топика для входящих и исходящих сообщений, соответствующих основной задаче (чтение) и задаче со звездочкой\* (запись). Все опции топиков оставим со значениями по умолчанию.

```shell
$ docker exec -it kafka1 bash

[appuser@kafka1 ~]$ kafka-topics --bootstrap-server localhost:9092 --topic github-incoming --create
Created topic github-incoming.

[appuser@kafka1 ~]$ kafka-topics --bootstrap-server localhost:9092 --topic github-outgoing --create
Created topic github-outgoing.

[appuser@kafka1 ~]$ kafka-topics --bootstrap-server localhost:9092 --list
github-incoming
github-outgoing
```

## Чтение из *Kafka*

![Kafka table engine](https://github.com/rklepov/OTUS-ClickHouse-2025-03/blob/main/2025-06-30_Kafka/hw17/kafka_to_clickhouse.png)

### Настройка *ClickHouse* для чтения

```sql
CREATE DATABASE IF NOT EXISTS hw17

Ok.


USE hw17

Ok.
```

Создаём таблицу со стандартным движком *MergeTree* для хранения данных.

```sql
CREATE OR REPLACE TABLE github
(
    `file_time` DateTime,
    `event_type` Enum('CommitCommentEvent' = 1, 'CreateEvent' = 2, 'DeleteEvent' = 3, 'ForkEvent' = 4, 'GollumEvent' = 5, 'IssueCommentEvent' = 6, 'IssuesEvent' = 7, 'MemberEvent' = 8, 'PublicEvent' = 9, 'PullRequestEvent' = 10, 'PullRequestReviewCommentEvent' = 11, 'PushEvent' = 12, 'ReleaseEvent' = 13, 'SponsorshipEvent' = 14, 'WatchEvent' = 15, 'GistEvent' = 16, 'FollowEvent' = 17, 'DownloadEvent' = 18, 'PullRequestReviewEvent' = 19, 'ForkApplyEvent' = 20, 'Event' = 21, 'TeamAddEvent' = 22),
    `actor_login` LowCardinality(String),
    `repo_name` LowCardinality(String),
    `created_at` DateTime,
    `updated_at` DateTime,
    `action` Enum('none' = 0, 'created' = 1, 'added' = 2, 'edited' = 3, 'deleted' = 4, 'opened' = 5, 'closed' = 6, 'reopened' = 7, 'assigned' = 8, 'unassigned' = 9, 'labeled' = 10, 'unlabeled' = 11, 'review_requested' = 12, 'review_request_removed' = 13, 'synchronize' = 14, 'started' = 15, 'published' = 16, 'update' = 17, 'create' = 18, 'fork' = 19, 'merged' = 20),
    `comment_id` UInt64,
    `path` String,
    `ref` LowCardinality(String),
    `ref_type` Enum('none' = 0, 'branch' = 1, 'tag' = 2, 'repository' = 3, 'unknown' = 4),
    `creator_user_login` LowCardinality(String),
    `number` UInt32,
    `title` String,
    `labels` Array(LowCardinality(String)),
    `state` Enum('none' = 0, 'open' = 1, 'closed' = 2),
    `assignee` LowCardinality(String),
    `assignees` Array(LowCardinality(String)),
    `closed_at` DateTime,
    `merged_at` DateTime,
    `merge_commit_sha` String,
    `requested_reviewers` Array(LowCardinality(String)),
    `merged_by` LowCardinality(String),
    `review_comments` UInt32,
    `member_login` LowCardinality(String)
)
ENGINE = MergeTree
ORDER BY (event_type, repo_name, created_at)

0 rows in set. Elapsed: 0.068 sec.
```

Создаём таблицу с движком [*Kafka*](https://clickhouse.com/docs/engines/table-engines/integrations/kafka) для чтения из топика `github-incoming`. Поскольку *Kafka* и *ClickHouse* работают в [виртуальной сети](https://docs.docker.com/engine/network/) *Docker*, то для подключения к брокеру *Kafka* надо использовать **INTERNAL** порт `19092`.

```sql
CREATE OR REPLACE TABLE github_incoming_queue
(
    `file_time` DateTime,
    `event_type` Enum('CommitCommentEvent' = 1, 'CreateEvent' = 2, 'DeleteEvent' = 3, 'ForkEvent' = 4, 'GollumEvent' = 5, 'IssueCommentEvent' = 6, 'IssuesEvent' = 7, 'MemberEvent' = 8, 'PublicEvent' = 9, 'PullRequestEvent' = 10, 'PullRequestReviewCommentEvent' = 11, 'PushEvent' = 12, 'ReleaseEvent' = 13, 'SponsorshipEvent' = 14, 'WatchEvent' = 15, 'GistEvent' = 16, 'FollowEvent' = 17, 'DownloadEvent' = 18, 'PullRequestReviewEvent' = 19, 'ForkApplyEvent' = 20, 'Event' = 21, 'TeamAddEvent' = 22),
    `actor_login` LowCardinality(String),
    `repo_name` LowCardinality(String),
    `created_at` DateTime,
    `updated_at` DateTime,
    `action` Enum('none' = 0, 'created' = 1, 'added' = 2, 'edited' = 3, 'deleted' = 4, 'opened' = 5, 'closed' = 6, 'reopened' = 7, 'assigned' = 8, 'unassigned' = 9, 'labeled' = 10, 'unlabeled' = 11, 'review_requested' = 12, 'review_request_removed' = 13, 'synchronize' = 14, 'started' = 15, 'published' = 16, 'update' = 17, 'create' = 18, 'fork' = 19, 'merged' = 20),
    `comment_id` UInt64,
    `path` String,
    `ref` LowCardinality(String),
    `ref_type` Enum('none' = 0, 'branch' = 1, 'tag' = 2, 'repository' = 3, 'unknown' = 4),
    `creator_user_login` LowCardinality(String),
    `number` UInt32,
    `title` String,
    `labels` Array(LowCardinality(String)),
    `state` Enum('none' = 0, 'open' = 1, 'closed' = 2),
    `assignee` LowCardinality(String),
    `assignees` Array(LowCardinality(String)),
    `closed_at` DateTime,
    `merged_at` DateTime,
    `merge_commit_sha` String,
    `requested_reviewers` Array(LowCardinality(String)),
    `merged_by` LowCardinality(String),
    `review_comments` UInt32,
    `member_login` LowCardinality(String)
)
ENGINE = Kafka
SETTINGS kafka_broker_list = 'kafka1:19092',
    kafka_topic_list = 'github-incoming',
    kafka_group_name = 'clickhouse',
    kafka_format = 'JSONEachRow'

0 rows in set. Elapsed: 0.030 sec.
```

Создаём материализованное представление для связи двух таблиц, созданных ранее.

```sql
CREATE MATERIALIZED VIEW github_mv TO github
AS SELECT *
FROM github_incoming_queue

0 rows in set. Elapsed: 0.059 sec.
```

Убедимся, что на текущий момент записи в целевой таблице **hw17.github** отсутствуют.

```sql
SELECT
    database,
    name,
    engine,
    total_rows,
    parts
FROM system.tables
WHERE database IN ('hw17')

   ┌─database─┬─name──────────────────┬─engine───────────┬─total_rows─┬─parts─┐
1. │ hw17     │ github                │ MergeTree        │          0 │     0 │
2. │ hw17     │ github_incoming_queue │ Kafka            │       ᴺᵁᴸᴸ │  ᴺᵁᴸᴸ │
3. │ hw17     │ github_mv             │ MaterializedView │       ᴺᵁᴸᴸ │  ᴺᵁᴸᴸ │
   └──────────┴───────────────────────┴──────────────────┴────────────┴───────┘

3 rows in set. Elapsed: 0.016 sec.
```

### Тестовый датасет

Датасет был предварительно загружен по [ссылке](https://datasets-documentation.s3.eu-west-3.amazonaws.com/kafka/github_all_columns.ndjson) (*121M*).

> Это фрагмент полного датасета, который содержит более 3 млрд. записей, и работа с которым через *ClickHouse* подробно описана в статье на [ghe.clickhouse.tech](https://ghe.clickhouse.tech/).

```shell
$ wget -q --no-check-certificate https://datasets-documentation.s3.eu-west-3.amazonaws.com/kafka/github_all_columns.ndjson

$ ls -hAlF github_all_columns.ndjson
-rw-r--r--. 1 rklepov rklepov 121M Mar 25  2022 github_all_columns.ndjson

$ wc -l github_all_columns.ndjson
200000 github_all_columns.ndjson
```

Формат данных файла &mdash; [`JSONEachRow`](https://clickhouse.com/docs/interfaces/formats/JSONEachRow). Это текстовый файл, каждая строка которого представляет собой объект JSON, соответствующий одной записи в таблице. Всего 200000 таких записей.

Пример одной записи (*для удобства восприятия JSON отформатирован*):

<details>

<summary>github_all_columns.ndjson (1)</summary>

```json
{
  "file_time": "2019-09-23 11:00:00",
  "event_type": "PullRequestReviewCommentEvent",
  "actor_login": "excitoon",
  "repo_name": "ClickHouse/ClickHouse",
  "created_at": "2019-09-23 11:25:54",
  "updated_at": "2019-09-23 11:25:54",
  "action": "created",
  "comment_id": "327062451",
  "path": "dbms/src/TableFunctions/TableFunctionS3.h",
  "ref": "",
  "ref_type": "none",
  "creator_user_login": "excitoon",
  "number": 5596,
  "title": "s3 table function and storage",
  "labels": [
    "can be tested",
    "pr-feature"
  ],
  "state": "closed",
  "assignee": "",
  "assignees": [],
  "closed_at": "2019-09-22 21:53:07",
  "merged_at": "2019-09-22 21:53:07",
  "merge_commit_sha": "2054f80623f0454b1aabeccbaffc49e17e005926",
  "requested_reviewers": [
    "stavrolia"
  ],
  "merged_by": "",
  "review_comments": 0,
  "member_login": ""
}
```

</details>

### Публикация в топик *Kafka*

Опубликуем датасет в топик *Kafka* `github-incoming` с помощью утилиты [`kcat`](https://docs.confluent.io/platform/current/tools/kafkacat-usage.html) (её предварительно необходимо установить). Поскольку мы будем обращаться к *Kafka* "снаружи" контейнера, то для подключения к брокеру *Kafka* надо использовать **EXTERNAL** порт `9092`. Запускаем `kcat` в режиме *Producer* (`-P`):

```shell
cat github_all_columns.ndjson | kcat -b localhost:9092 -t github-incoming -P
```

### Проверка загруженных данных в *ClickHouse*

Вернёмся в консоль *ClickHouse* и повторим запрос для проверки состояния таблицы **hw17.github**:

```sql
SELECT
    database,
    name,
    engine,
    total_rows,
    parts
FROM system.tables
WHERE database IN ('hw17')

   ┌─database─┬─name──────────────────┬─engine───────────┬─total_rows─┬─parts─┐
1. │ hw17     │ github                │ MergeTree        │     200000 │     4 │
2. │ hw17     │ github_incoming_queue │ Kafka            │       ᴺᵁᴸᴸ │  ᴺᵁᴸᴸ │
3. │ hw17     │ github_mv             │ MaterializedView │       ᴺᵁᴸᴸ │  ᴺᵁᴸᴸ │
   └──────────┴───────────────────────┴──────────────────┴────────────┴───────┘

3 rows in set. Elapsed: 0.150 sec.
```

Как можно видеть, в ней появились 200000 записей.

<a name="github-table-excerpt"></a>
Для примера посмотрим на фрагмент загруженных данных:

```sql
SELECT
    created_at,
    actor_login,
    path
FROM hw17.github
WHERE (actor_login NOT IN ('robot-clickhouse')) AND (event_type IN ('PullRequestReviewCommentEvent'))
ORDER BY created_at ASC
LIMIT 15

    ┌──────────created_at─┬─actor_login──────┬─path───────────────────────────────────────────┐
 1. │ 2019-09-23 11:25:54 │ excitoon         │ dbms/src/TableFunctions/TableFunctionS3.h      │
 2. │ 2019-09-23 11:27:59 │ excitoon         │ dbms/src/TableFunctions/TableFunctionS3.h      │
 3. │ 2019-09-23 11:29:26 │ excitoon         │ dbms/src/Storages/StorageS3.h                  │
 4. │ 2019-09-23 11:32:43 │ excitoon         │ dbms/src/Storages/StorageS3.cpp                │
 5. │ 2019-09-23 11:33:03 │ excitoon         │ dbms/src/Storages/StorageS3.h                  │
 6. │ 2019-09-23 11:35:06 │ excitoon         │ dbms/src/IO/WriteBufferFromS3.h                │
 7. │ 2019-09-23 11:35:10 │ excitoon         │ dbms/src/IO/WriteBufferFromS3.h                │
 8. │ 2019-09-23 12:22:29 │ stavrolia        │ dbms/src/Storages/StorageFile.cpp              │
 9. │ 2019-09-23 12:42:35 │ abyss7           │ cmake/target.cmake                             │
10. │ 2019-09-23 12:44:26 │ excitoon         │ dbms/src/Storages/StorageS3.cpp                │
11. │ 2019-09-23 13:38:12 │ alexey-milovidov │ dbms/src/Storages/StorageFile.cpp              │
12. │ 2019-09-23 14:46:28 │ abyss7           │ cmake/target.cmake                             │
13. │ 2019-09-23 15:01:31 │ blinkov          │ docs/en/query_language/table_functions/hdfs.md │
14. │ 2019-09-23 15:11:22 │ stavrolia        │ docs/en/query_language/table_functions/hdfs.md │
15. │ 2019-09-23 15:14:16 │ proller          │ cmake/find/snappy.cmake                        │
    └─────────────────────┴──────────────────┴────────────────────────────────────────────────┘

15 rows in set. Elapsed: 0.102 sec. Processed 60.14 thousand rows, 1.69 MB (591.99 thousand rows/s., 16.63 MB/s.)
Peak memory usage: 108.86 KiB.
```

## Запись в *Kafka* \*

Попробуем решить задачу публикации фрагмента данных из примера [выше](#github-table-excerpt) в топик *Kafka* `github-outgoing`.

Создаём таблицу с движком *Kafka* для исходящих данных. Хотя для публикации данных в *Kafka* не требуется указывать [*consumer group*](https://docs.confluent.io/platform/current/clients/consumer.html#consumer-groups), тем не менее в *ClickHouse* на сегодняшний день нет специализированного табличного движка только для *Kafka Producer*, поэтому здесь тоже приходится задавать обязательный параметр `kafka_group_name`. Данные будем записывать в формате CSV.

```sql
CREATE OR REPLACE TABLE github_outgoing_queue
(
    `created_at` DateTime,
    `actor_login` LowCardinality(String),
    `path` String
)
ENGINE = Kafka
SETTINGS kafka_broker_list = 'kafka1:19092',
    kafka_topic_list = 'github-outgoing',
    kafka_group_name = 'clickhouse',
    kafka_format = 'CSV'

0 rows in set. Elapsed: 0.026 sec.
```

Далее просто выполняем `INSERT` фрагмента данных из таблицы **hw17.github** в созданную таблицу.

```sql
INSERT INTO github_outgoing_queue SELECT
    created_at,
    actor_login,
    path
FROM hw17.github
WHERE (actor_login NOT IN ('robot-clickhouse')) AND (event_type IN ('PullRequestReviewCommentEvent'))
ORDER BY created_at ASC
LIMIT 15

0 rows in set. Elapsed: 0.577 sec. Processed 60.14 thousand rows, 1.69 MB (104.19 thousand rows/s., 2.93 MB/s.)
Peak memory usage: 107.94 KiB.
```

Прочитаем сообщения, записанные в топик `github-outgoing`, запустив `kcat` в режиме *Consumer* (`-C`):

```shell
$ kcat -b localhost:9092 -t github-outgoing -C

"2019-09-23 11:25:54","excitoon","dbms/src/TableFunctions/TableFunctionS3.h"

"2019-09-23 11:27:59","excitoon","dbms/src/TableFunctions/TableFunctionS3.h"

"2019-09-23 11:29:26","excitoon","dbms/src/Storages/StorageS3.h"

"2019-09-23 11:32:43","excitoon","dbms/src/Storages/StorageS3.cpp"

"2019-09-23 11:33:03","excitoon","dbms/src/Storages/StorageS3.h"

"2019-09-23 11:35:06","excitoon","dbms/src/IO/WriteBufferFromS3.h"

"2019-09-23 11:35:10","excitoon","dbms/src/IO/WriteBufferFromS3.h"

"2019-09-23 12:22:29","stavrolia","dbms/src/Storages/StorageFile.cpp"

"2019-09-23 12:42:35","abyss7","cmake/target.cmake"

"2019-09-23 12:44:26","excitoon","dbms/src/Storages/StorageS3.cpp"

"2019-09-23 13:38:12","alexey-milovidov","dbms/src/Storages/StorageFile.cpp"

"2019-09-23 14:46:28","abyss7","cmake/target.cmake"

"2019-09-23 15:01:31","blinkov","docs/en/query_language/table_functions/hdfs.md"

"2019-09-23 15:11:22","stavrolia","docs/en/query_language/table_functions/hdfs.md"

"2019-09-23 15:14:16","proller","cmake/find/snappy.cmake"

% Reached end of topic github-outgoing [0] at offset 15
```

Как можно убедиться, действительно было получено 15 сообщений, соответствущих [результату](#github-table-excerpt) `SELECT`. Данные в формате CSV, как и было указано при создании таблицы `github_outgoing_queue`.

## Пайплайн обработки данных без использования *Kafka Engine* \*\*

*Изучение [Kafka Connect](https://docs.confluent.io/platform/current/connect/userguide.html) &mdash; это отдельная трудоёмкая задача, поэтому я пока отложил её в бэклог*.
